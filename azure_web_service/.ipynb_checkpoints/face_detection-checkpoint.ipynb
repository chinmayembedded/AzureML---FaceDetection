{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries\n",
    "### Introduction\n",
    "This example shows the deployment of pretrained face recognition model. Before proceeding create the workspace with the **00.configuration.ipynb**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Machine Learning SDK version is 0.1.0.1217125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Project, Run\n",
    "print (\"Azure Machine Learning SDK version is\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the workspace\n",
    "Load the workspace created in **00.configuration.ipynb.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: D:\\AnacondaProjects\\AzureMLPreview-master-17august\\notebooks\\aml_config\\config.json\n",
      "face_recognition_ws_copy\teastus2\tface_recognition_rg_copy\teastus2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create score.py file\n",
    "Create a **score.py** which loads the deployed model in __*init()*__ function.\n",
    "__*run()*__ funtion takes the base64 image as an input. Base64 image is then converted into nparray for the recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import cv2\n",
    "import base64 \n",
    "from PIL import Image\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "category_index = {2: {'id': 2, 'name': 'background'}, 1: {'id': 1, 'name': 'face'}}\n",
    "detection_graph = tf.Graph()\n",
    "sess = None\n",
    "def init():\n",
    "    global sess\n",
    "    model_root = Model.get_model_path('frmodel')\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(model_root, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    with detection_graph.as_default():\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            sess = tf.Session(graph=detection_graph, config=config)\n",
    "    \n",
    "def run(image):\n",
    "    str = json.loads(image)['data']\n",
    "    imgdata = base64.b64decode(str)\n",
    "    data = Image.open(io.BytesIO(imgdata))\n",
    "    image = cv2.cvtColor(np.array(data), cv2.COLOR_BGR2RGB)\n",
    "    image_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "            [boxes, scores, classes, num_detections],\n",
    "            feed_dict={image_tensor: image_np_expanded})\n",
    "    result = json.dumps({\"boxes\" : boxes.tolist(), \"classes\" : classes.tolist(), \"scores\": scores.tolist(), \"num_detections\": num_detections.tolist()})\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create myenv.yml\n",
    "We also need to create an environment file that can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify below mentioned packages in myenv.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting myenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - numpy\n",
    "    - tensorflow==1.4.0\n",
    "    # Required packages for AzureML execution, history, and data preparation.\n",
    "    - --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n",
    "    - azureml-core\n",
    "    - Pillow\n",
    "    - opencv-python-headless\n",
    "    - opencv-contrib-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deploy to ACI\n",
    "Create a deployment configuration file and specify the number of CPUs and gigbyte of RAM needed for your ACI container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = ['FACE_RECOGNITION'], \n",
    "                                               description = 'Tensorflow FR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a container image\n",
    "to create a container image, we are required to give the __execution_script__, __runtime__ and __conda environment files__.\n",
    "\n",
    "### Register the model\n",
    "As we have pretrained model, we need to specify the __model path__, __model name__, and __workspace__ on which the model to be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model frmodel\n",
      "<azureml.core.model.Model object at 0x000001E257570630>\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.model import Model\n",
    "# Container image configuration\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\", \n",
    "                                                  runtime = \"python\", \n",
    "                                                  conda_file = \"myenv.yml\")\n",
    "\n",
    "# Model registration\n",
    "model1 = Model.register(model_path = \"./model/frozen_inference_graph_face.pb\",\n",
    "                       model_name = \"frmodel\",\n",
    "                       tags = [\"facerecognition\"],\n",
    "                       description = \"Face recognition model\",\n",
    "                       workspace = ws)\n",
    "\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the service\n",
    "This script will run for about 10-12 minutes. Behind the scene, it takes the local model folder and register it (and the files inside that folder) as a model named model __under the workspace__. It then builds a Docker image using the scoring file, the environment file, and the model files. It then registers that image under the workspace. And it finally ships the image to the ACI infrastructure, starts up a container in ACI using that image, and exposes an HTTP endpoint to accept REST client calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image tffrcopy:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Webservice.deploy_from_model(workspace = ws,\n",
    "                                       name = 'tffacerecognition',\n",
    "                                       deployment_config = aciconfig,\n",
    "                                       models = [model1],\n",
    "                                       image_config = image_config)\n",
    "\n",
    "\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the service\n",
    "The following code is helpful if we want to check the logs of the service if it fails to build. We need to specify the web service name in the given workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: D:\\AnacondaProjects\\AzureMLPreview-master-17august\\notebooks\\aml_config\\config.json\n",
      "tffr tffr:14\n",
      "tffr tffr:13\n",
      "tffr tffr:12\n",
      "tffr tffr:11\n",
      "tffr tffr:10\n",
      "tffr tffr:9\n",
      "tffr tffr:8\n",
      "tffr tffr:7\n",
      "tffr tffr:6\n",
      "tffr tffr:5\n",
      "tf-mnist tf-mnist:1\n",
      "tffr tffr:4\n",
      "tffr tffr:3\n",
      "tffr tffr:2\n",
      "tffr tffr:1\n",
      "tffr\n",
      "tf-mnist\n",
      "2018-08-22 05:24:37,469 CRIT Supervisor running as root (no user in config file)\n",
      "2018-08-22 05:24:37,471 INFO supervisord started with pid 1\n",
      "2018-08-22 05:24:38,473 INFO spawned: 'rsyslog' with pid 7\n",
      "2018-08-22 05:24:38,474 INFO spawned: 'program_exit' with pid 8\n",
      "2018-08-22 05:24:38,475 INFO spawned: 'nginx' with pid 9\n",
      "2018-08-22 05:24:38,476 INFO spawned: 'iot' with pid 10\n",
      "2018-08-22 05:24:38,541 INFO spawned: 'gunicorn' with pid 11\n",
      "2018-08-22 05:24:38,572 INFO success: iot entered RUNNING state, process has stayed up for > than 0 seconds (startsecs)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2018-08-22 05:24:38,670 INFO exited: iot (exit status 1; expected)\n",
      "2018-08-22 05:24:39,672 INFO success: rsyslog entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\n",
      "2018-08-22 05:24:39,672 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\n",
      "2018-08-22 05:24:43,676 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Starting gunicorn %s\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:43.956447Z\", \"message\": \"Starting gunicorn 19.6.0\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Listening at: %s (%s)\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:43.958138Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (11)\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Using worker: %s\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:43.958510Z\", \"message\": \"Using worker: sync\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:43.959342Z\", \"message\": \"worker timeout is set to 300\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Booting worker with pid: %s\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:43.960267Z\", \"message\": \"Booting worker with pid: 24\"}\n",
      "{\"level\": \"ERROR\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/arbiter.py\\\", line 557, in spawn_worker\\n    worker.init_process()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/workers/base.py\\\", line 126, in init_process\\n    self.load_wsgi()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/workers/base.py\\\", line 136, in load_wsgi\\n    self.wsgi = self.app.wsgi()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/base.py\\\", line 67, in wsgi\\n    self.callable = self.load()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/wsgiapp.py\\\", line 65, in load\\n    return self.load_wsgiapp()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/wsgiapp.py\\\", line 52, in load_wsgiapp\\n    return util.import_app(self.app_uri)\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/util.py\\\", line 357, in import_app\\n    __import__(module)\\n  File \\\"/var/azureml-app/wsgi.py\\\", line 1, in <module>\\n    from create_app import create\\n  File \\\"/var/azureml-app/create_app.py\\\", line 4, in <module>\\n    from app import main\\n  File \\\"/var/azureml-app/app.py\\\", line 5, in <module>\\n    from aml_blueprint import AMLBlueprint\\n  File \\\"/var/azureml-app/aml_blueprint.py\\\", line 11, in <module>\\n    import main\\n  File \\\"/var/azureml-app/main.py\\\", line 13, in <module>\\n    driver_module_spec.loader.exec_module(driver_module)\\n  File \\\"score.py\\\", line 8, in <module>\\n    import cv2\\nImportError: No module named 'cv2'\\n\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"filename\": \"glogging.py\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:45.769674Z\", \"lineno\": 253, \"message\": \"Exception in worker process\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Worker exiting (pid: %s)\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:45.770498Z\", \"message\": \"Worker exiting (pid: 24)\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Shutting down: %s\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:45.926937Z\", \"message\": \"Shutting down: Master\"}\n",
      "{\"level\": \"INFO\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"msg\": \"Reason: %s\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"logger\": \"gunicorn.error\", \"stack_info\": null, \"timestamp\": \"2018-08-22T05:24:45.927186Z\", \"message\": \"Reason: Worker failed to boot.\"}\n",
      "2018-08-22 05:24:45,951 INFO exited: gunicorn (exit status 3; not expected)\n",
      "2018-08-22 05:24:46,953 INFO spawned: 'gunicorn' with pid 27\n",
      "{\"timestamp\": \"2018-08-22T05:24:52.367304Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Starting gunicorn 19.6.0\", \"msg\": \"Starting gunicorn %s\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:52.368351Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Listening at: http://127.0.0.1:9090 (27)\", \"msg\": \"Listening at: %s (%s)\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:52.368710Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Using worker: sync\", \"msg\": \"Using worker: %s\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:52.369501Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"worker timeout is set to 300\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:52.370423Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Booting worker with pid: 31\", \"msg\": \"Booting worker with pid: %s\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:53.720813Z\", \"lineno\": 253, \"stack_info\": null, \"level\": \"ERROR\", \"filename\": \"glogging.py\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Exception in worker process\", \"exc_info\": \"Traceback (most recent call last):\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/arbiter.py\\\", line 557, in spawn_worker\\n    worker.init_process()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/workers/base.py\\\", line 126, in init_process\\n    self.load_wsgi()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/workers/base.py\\\", line 136, in load_wsgi\\n    self.wsgi = self.app.wsgi()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/base.py\\\", line 67, in wsgi\\n    self.callable = self.load()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/wsgiapp.py\\\", line 65, in load\\n    return self.load_wsgiapp()\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/app/wsgiapp.py\\\", line 52, in load_wsgiapp\\n    return util.import_app(self.app_uri)\\n  File \\\"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/util.py\\\", line 357, in import_app\\n    __import__(module)\\n  File \\\"/var/azureml-app/wsgi.py\\\", line 1, in <module>\\n    from create_app import create\\n  File \\\"/var/azureml-app/create_app.py\\\", line 4, in <module>\\n    from app import main\\n  File \\\"/var/azureml-app/app.py\\\", line 5, in <module>\\n    from aml_blueprint import AMLBlueprint\\n  File \\\"/var/azureml-app/aml_blueprint.py\\\", line 11, in <module>\\n    import main\\n  File \\\"/var/azureml-app/main.py\\\", line 13, in <module>\\n    driver_module_spec.loader.exec_module(driver_module)\\n  File \\\"score.py\\\", line 8, in <module>\\n    import cv2\\nImportError: No module named 'cv2'\\n\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:53.721603Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Worker exiting (pid: 31)\", \"msg\": \"Worker exiting (pid: %s)\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:53.870975Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Shutting down: Master\", \"msg\": \"Shutting down: %s\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "{\"timestamp\": \"2018-08-22T05:24:53.871234Z\", \"stack_info\": null, \"level\": \"INFO\", \"host\": \"caas-1a98ebd239024bf386cd81bc49d98233-6df6978d98-xgcwf\", \"message\": \"Reason: Worker failed to boot.\", \"msg\": \"Reason: %s\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"logger\": \"gunicorn.error\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\"}\n",
      "2018-08-22 05:24:53,894 INFO exited: gunicorn (exit status 3; not expected)\n",
      "2018-08-22 05:24:54,895 INFO gave up: gunicorn entered FATAL state, too many start retries too quickly\n",
      "2018-08-22 05:24:55,897 WARN program_exit: bad result line: 'Killing supervisor with this event: ver:3.0 server:supervisor serial:0 pool:program_exit poolserial:0 eventname:PROCESS_STATE_FATAL len:58'\n",
      "2018-08-22 05:24:55,897 WARN program_exit: has entered the UNKNOWN state and will no longer receive events, this usually indicates the process violated the eventlistener protocol\n",
      "2018-08-22 05:24:55,897 WARN received SIGQUIT indicating exit request\n",
      "2018-08-22 05:24:55,897 INFO waiting for nginx, rsyslog, program_exit to die\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Lists the images\n",
    "for img in ws.images(): \n",
    "    print (img.name, img.id)\n",
    "\n",
    "# Lists the web services \n",
    "for s in ws.webservices():\n",
    "    print(s.name)\n",
    "\n",
    "# instantiate the web service object from workspace and service name\n",
    "svc = Webservice(workspace = ws, name = 'tffacerecognition')\n",
    "\n",
    "# print out the Docker log\n",
    "print(svc.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring URI\n",
    "the web service uri can be obtained here. \n",
    "#### Request format\n",
    "/POST query\n",
    "<br>\n",
    "content-type - application/json\n",
    "<br>\n",
    "Request data - {\"data\" : \"<base64 payload of an image>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://104.211.23.181:5001/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
